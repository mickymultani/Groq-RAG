# Ultra-Fast RAG Chatbot with Groq's LPU

Let's build an ultra-fast RAG Chatbot using Groq's Language Processing Unit (LPU), LangChain, and Ollama. This project is designed to provide users with the ability to interactively query PDF documents, leveraging the unprecedented speed of Groq's specialized hardware for language models.

## Introduction

The chatbot utilizes Groq's LPU to overcome traditional bottlenecks in processing Large Language Models (LLMs), offering incredibly fast inference times. Coupled with LangChain for seamless integration and manipulation of language models and data, and Gradio for creating an intuitive user interface, this project sets a new standard for document-based question-answering systems.

## Getting Started

This section will guide you through the setup process, ensuring that you have all the necessary tools and knowledge to get the chatbot up and running.

### Prerequisites

- Python 3.x environment
- Groq API key (obtainable from [GroqCloud Playground](https://console.groq.com/playground))

### Installation

#### Install Dependencies

Install all required Python packages using pip:

```
pip install groq langchain langchain-core langchain-groq chromadb pypdf gradio
```
## Follow the colab!
